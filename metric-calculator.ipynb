{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Metric Calculator\n",
        "##### Author : Kunal Kalwankar"
      ],
      "metadata": {
        "id": "gTtVMxJ1B12f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3CMcmt_XTRi"
      },
      "outputs": [],
      "source": [
        "# imports and config\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/cnn_dailymail')\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install spacy\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ls9TL5pF8aWT"
      },
      "outputs": [],
      "source": [
        "# Import the tag files for clusters and files that signify testids\n",
        "\n",
        "d1 = pd.read_csv('t5small_knn5_5epochs_0_.csv')\n",
        "d2 = pd.read_csv('t5small_knn5_5epochs_1_.csv')\n",
        "d3 = pd.read_csv('t5small_knn5_5epochs_2_.csv')\n",
        "d4 = pd.read_csv('t5small_knn5_5epochs_3_.csv')\n",
        "d5 = pd.read_csv('t5small_knn5_5epochs_4_.csv')\n",
        "\n",
        "t1 = pd.read_csv('testids_1_to_5.csv')\n",
        "t2 = pd.read_csv('testids_2_to_5.csv')\n",
        "t3 = pd.read_csv('testids_3_to_5.csv')\n",
        "t4 = pd.read_csv('testids_4_to_5.csv')\n",
        "t5 = pd.read_csv('testids_5_to_5.csv')\n",
        "\n",
        "d = pd.concat([d1,d2,d3,d4,d5])\n",
        "t = pd.concat([t1,t2,t3,t4,t5])\n",
        "data = d.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYdei1JPZno7"
      },
      "outputs": [],
      "source": [
        "#Filter only for testids and required columns\n",
        "data1 = data[data['id'].isin(list(t['TESTIDS']))]\n",
        "data1.shape\n",
        "data1 = data1[['article','highlights','predictions']]\n",
        "x = data1.copy()\n",
        "x = x[['predictions','highlights','article']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mKJ55r0jkSj"
      },
      "outputs": [],
      "source": [
        "# pruner function removes the brackets '[]' and inverted commas since simpleT5 generates in a list format\n",
        "def pruner(obj):\n",
        "  return obj[2:][:-2]\n",
        "x['predictions'] = x['predictions'].apply(pruner)\n",
        "print(x.head())\n",
        "data = x.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUEaHE5e1AgF"
      },
      "outputs": [],
      "source": [
        "#SPACY TEST OUTPUT\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "sentence = \"Apple is looking at buying a U.K. startup for $1 billion\"\n",
        "doc = nlp(sentence)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhsJYum3F493"
      },
      "outputs": [],
      "source": [
        "data['article'] = data['article'].str.lower()\n",
        "data['highlights'] = data['highlights'].str.lower()\n",
        "data['predictions'] = data['predictions'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2e2qWaJ1QgL"
      },
      "outputs": [],
      "source": [
        "#ENTITY HALLUCAINATION FUNCTIONS\n",
        "\n",
        "def entity_filter(text):\n",
        "  doc = nlp(text)\n",
        "  entity_list = [ent.text for ent in doc.ents]\n",
        "  return entity_list\n",
        "\n",
        "def entity_hallucination(text,summ):\n",
        "  metric_counter = []\n",
        "  t = [entity_filter(i) for i in text]\n",
        "  s = [entity_filter(k) for k in summ]\n",
        "\n",
        "  for n,i in enumerate(t[:10]):\n",
        "    ent_count = len(t[n])\n",
        "    false_ent_count = [j for j in s[n] if j not in t[n]]\n",
        "    flase_ent_count = len(ent_correct_count)\n",
        "    try:\n",
        "      x = (false_ent_count/ent_count)\n",
        "    except:\n",
        "      x=0\n",
        "    metric_counter.append(x)\n",
        "  \n",
        "  try:\n",
        "    return sum(metric_counter)/len(metric_counter)\n",
        "  except:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL5I0jAW3TK8"
      },
      "outputs": [],
      "source": [
        "#ROUGE METRICS\n",
        "\n",
        "!pip install rouge_score\n",
        "!pip install datasets\n",
        "!pip install datasets\n",
        "from datasets import load_metric\n",
        "metric = load_metric(\"rouge\")\n",
        "\n",
        "def calc_rouge_scores(candidates, references):\n",
        "    result = metric.compute(predictions=candidates, references=references, use_stemmer=True)\n",
        "    result = {key: round(value.mid.fmeasure * 100, 1) for key, value in result.items()}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC1omjh5kc80"
      },
      "outputs": [],
      "source": [
        "# ENTITY HALLUCINATION WITH REPECT TO GOLDER SUMMARY\n",
        "print(entity_hallucination(data['highlights'],data['predictions']))\n",
        "\n",
        "# ENTITY HALLUCINATION WITH REPECT TO ARTICLE\n",
        "print(entity_hallucination(data['article'],data['predictions']))\n",
        "\n",
        "#CALCULATE ROUGE SCORES\n",
        "print(calc_rouge_scores(list(data['predictions']), list(data['highlights'])))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}