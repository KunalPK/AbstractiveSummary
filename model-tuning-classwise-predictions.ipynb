{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### CLASSWISE MODEL TUNING CODE\n##### Author : Kunal Kalwankar","metadata":{}},{"cell_type":"code","source":"#Imports\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport torch\nimport json\nimport numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nimport os\n!pip install simpleT5\nfrom simplet5 import SimpleT5\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing pre deicded testids for all the topics. These were split 90-10 only once for all iterations and saved\nos.listdir('/kaggle/input/cnndm-tagged-subset')\ndata_init = pd.read_csv('/kaggle/input/cnndm-tagged-subset/masterdata.csv')\nt1 = pd.read_csv('/kaggle/input/testids/testids_1_to_5.csv')\nt2 = pd.read_csv('/kaggle/input/testids/testids_2_to_5.csv')\nt3 = pd.read_csv('/kaggle/input/testids/testids_3_to_5.csv')\nt4 = pd.read_csv('/kaggle/input/testids/testids_4_to_5.csv')\nt5 = pd.read_csv('/kaggle/input/testids/testids_5_to_5.csv')\nt = pd.concat([t1,t2,t3,t4,t5])\n\n#maximum epochs\nMAX_EPOCHS = 3\n\n#import knn tags or topic tags based on autoNLP\nknn = pd.read_csv('/kaggle/input/knn5tags/KNN5.csv')[['classname']]\n\n#check distribution\nprint(knn['classname'].value_counts())\n\n#join the tags to dataset\ndata_init = pd.concat([data_init,knn],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Iterative training that goes on for hours. One model is trained and saved per value in the list.\n#Each checkpoint after\n\nls = [0,1,2,3,4]\nfor i in ls:\n    data = data_init[data_init['classname']==i]\n    \n    #Hyperpaarmeters\n    MAX_LEN = 512\n    SUMMARY_LEN = 150\n    \n    #select train and test\n    test = data[data['id'].isin(list(t['TESTIDS']))]\n    train = data[~data['id'].isin(list(t['TESTIDS']))]\n    TRAINING_SIZE = train.shape[0]\n    training_df = train.copy()\n    training_article_ls = list(training_df['article'])\n    training_highlight_ls = list(training_df['highlights'])\n    df = pd.DataFrame(columns=['target_text','source_text'])\n    \n    # manipulate inputs\n    df['target_text'] = training_highlight_ls\n    df['source_text'] = ['summarize: '+item for item in training_article_ls]\n    model = SimpleT5()\n    model.from_pretrained(model_type=\"t5\", model_name=\"t5-small\")\n    t1 = time.time()\n    \n    #70-30 splits\n    model.train(train_df=df[0:(int)(0.7*TRAINING_SIZE)],\n                eval_df=df[(int)(0.7*TRAINING_SIZE):TRAINING_SIZE], \n                source_max_token_len=MAX_LEN, \n                target_max_token_len=SUMMARY_LEN, \n                batch_size=8, max_epochs=MAX_EPOCHS, use_gpu=True)\n    print(time.time()-t1)\n    \n    # save model \n    l = os.listdir('/kaggle/working/outputs')  \n    modelname = [g for g in l if 'simplet5-epoch-2' in g]\n    modelname = [i for i in modelname if i not in used_models]\n    used_models.append(modelname[0])\n    modelname=modelname[0]\n    model.load_model(\"t5\",\"outputs/\"+modelname, use_gpu=True)\n    print(modelname)\n    articles = list(test['article'])\n    \n    #prediction function\n    def prediction(x):\n        return model.predict(x)\n    store = [prediction(g) for g in articles]\n    test['predictions'] = store\n    \n    #Save file with predictions to pass to metric calculator\n    test.to_csv('t5small_knn5_5epochs_'+str(i)+'_.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}