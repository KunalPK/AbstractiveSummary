{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### MODEL TUNING CODE\n##### Author : Kunal Kalwankar","metadata":{}},{"cell_type":"code","source":"#Imports\nimport numpy as np\nimport pandas as pd\nimport os      \nimport torch\nimport json\n!pip install simplet5\nimport torch\nimport json \nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-14T08:40:08.060336Z","iopub.execute_input":"2023-01-14T08:40:08.060864Z","iopub.status.idle":"2023-01-14T08:40:41.713803Z","shell.execute_reply.started":"2023-01-14T08:40:08.060818Z","shell.execute_reply":"2023-01-14T08:40:41.712742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import pretrained model\nfrom simplet5 import SimpleT5\nmodel = SimpleT5()\nmodel.from_pretrained(model_type=\"t5\", model_name=\"t5-base\")","metadata":{"execution":{"iopub.status.busy":"2023-01-14T08:45:58.450840Z","iopub.execute_input":"2023-01-14T08:45:58.451620Z","iopub.status.idle":"2023-01-14T08:46:18.538206Z","shell.execute_reply.started":"2023-01-14T08:45:58.451582Z","shell.execute_reply":"2023-01-14T08:46:18.536863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing pre deicded testids for all the topics. These were split 90-10 only once for all iterations and saved\nimport os\nos.listdir('/kaggle/input/cnndm-tagged-subset')\ndata = pd.read_csv('/kaggle/input/cnndm-tagged-subset/masterdata.csv')\nt1 = pd.read_csv('/kaggle/input/testids/testids_1_to_5.csv')\nt2 = pd.read_csv('/kaggle/input/testids/testids_2_to_5.csv')\nt3 = pd.read_csv('/kaggle/input/testids/testids_3_to_5.csv')\nt4 = pd.read_csv('/kaggle/input/testids/testids_4_to_5.csv')\nt5 = pd.read_csv('/kaggle/input/testids/testids_5_to_5.csv')\nt = pd.concat([t1,t2,t3,t4,t5])\ntest = data[data['id'].isin(list(t['TESTIDS']))]\ntrain = data[~data['id'].isin(list(t['TESTIDS']))]","metadata":{"execution":{"iopub.status.busy":"2023-01-14T08:57:51.176278Z","iopub.execute_input":"2023-01-14T08:57:51.176878Z","iopub.status.idle":"2023-01-14T08:57:53.520877Z","shell.execute_reply.started":"2023-01-14T08:57:51.176828Z","shell.execute_reply":"2023-01-14T08:57:53.519886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nMAX_LEN = 512\nSUMMARY_LEN = 150\n\n# Getting test datapoints\ntest_article = list(test['article'])[250:]\ntest_highlight = list(test['highlights'])[250:]","metadata":{"execution":{"iopub.status.busy":"2023-01-14T08:57:57.208003Z","iopub.execute_input":"2023-01-14T08:57:57.208370Z","iopub.status.idle":"2023-01-14T08:57:57.215222Z","shell.execute_reply.started":"2023-01-14T08:57:57.208339Z","shell.execute_reply":"2023-01-14T08:57:57.214197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import pretrained model\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\nno_tune_model = T5ForConditionalGeneration.from_pretrained('t5-base')\ntokenizer = T5Tokenizer.from_pretrained('t5-base')\ndevice = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2023-02-01T17:52:10.667664Z","iopub.execute_input":"2023-02-01T17:52:10.668276Z","iopub.status.idle":"2023-02-01T17:53:03.452796Z","shell.execute_reply.started":"2023-02-01T17:52:10.668172Z","shell.execute_reply":"2023-02-01T17:53:03.451290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preprocess the test inputs sequenctially to get in the final format\npreprocess_text = [i.strip().replace(\"\\n\",\"\") for i in test_article]\nt5_prepared_Text = [\"summarize: \"+i for i in preprocess_text]\ntokenized_text = [tokenizer.encode(i, return_tensors=\"pt\").to(device) for i in t5_prepared_Text]\nsummary_ids = [no_tune_model.generate(i,\n                                    num_beams=4,\n                                    no_repeat_ngram_size=2,\n                                    min_length=30,\n                                    max_length=SUMMARY_LEN,\n                                    early_stopping=True) for i in tokenized_text]\n\noutput = [tokenizer.decode(i[0], skip_special_tokens=True) for i in summary_ids]\n\n\n#Save the predicted outcode for metric calculator\nnotune = pd.DataFrame({'outcome':list(output)})\nnotune.to_csv('outcomenotune_t5base_1.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-14T08:58:00.554200Z","iopub.execute_input":"2023-01-14T08:58:00.554601Z","iopub.status.idle":"2023-01-14T08:58:14.816563Z","shell.execute_reply.started":"2023-01-14T08:58:00.554566Z","shell.execute_reply":"2023-01-14T08:58:14.815573Z"},"trusted":true},"execution_count":null,"outputs":[]}]}